{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf832729",
   "metadata": {},
   "source": [
    "# Modeling- Part 2 (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ace4aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve, cross_val_score, RandomizedSearchCV, validation_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, accuracy_score, classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from bayes_opt import BayesianOptimization\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression, SelectKBest, f_regression\n",
    "from sklearn.utils import resample, shuffle\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57bac9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To suppress future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3268495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('/Users/josephlim/Desktop/Data Science/Capstone Projects/Capstone project- Spotify/spotify_data_preprocessed_exp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d24b2307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(587927, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b73c1d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.06</td>\n",
       "      <td>126903</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.4450</td>\n",
       "      <td>-13.338</td>\n",
       "      <td>0.4510</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.7440</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.127</td>\n",
       "      <td>104.851</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>98200</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.2630</td>\n",
       "      <td>-22.136</td>\n",
       "      <td>0.9570</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.655</td>\n",
       "      <td>102.009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>181640</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>-21.180</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.457</td>\n",
       "      <td>130.418</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>176907</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.0946</td>\n",
       "      <td>-27.961</td>\n",
       "      <td>0.0504</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.9180</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.397</td>\n",
       "      <td>169.980</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>163080</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>-16.900</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.196</td>\n",
       "      <td>103.220</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  duration_ms  danceability  energy  loudness  speechiness  \\\n",
       "0        0.06       126903         0.645  0.4450   -13.338       0.4510   \n",
       "1        0.00        98200         0.695  0.2630   -22.136       0.9570   \n",
       "2        0.00       181640         0.434  0.1770   -21.180       0.0512   \n",
       "3        0.00       176907         0.321  0.0946   -27.961       0.0504   \n",
       "4        0.00       163080         0.402  0.1580   -16.900       0.0390   \n",
       "\n",
       "   acousticness  instrumentalness  liveness  valence    tempo  time_signature  \n",
       "0         0.674            0.7440     0.151    0.127  104.851               3  \n",
       "1         0.797            0.0000     0.148    0.655  102.009               1  \n",
       "2         0.994            0.0218     0.212    0.457  130.418               5  \n",
       "3         0.995            0.9180     0.104    0.397  169.980               3  \n",
       "4         0.989            0.1300     0.311    0.196  103.220               4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "333a0bd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 587927 entries, 0 to 587926\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   popularity        587927 non-null  float64\n",
      " 1   duration_ms       587927 non-null  int64  \n",
      " 2   danceability      587927 non-null  float64\n",
      " 3   energy            587927 non-null  float64\n",
      " 4   loudness          587927 non-null  float64\n",
      " 5   speechiness       587927 non-null  float64\n",
      " 6   acousticness      587927 non-null  float64\n",
      " 7   instrumentalness  587927 non-null  float64\n",
      " 8   liveness          587927 non-null  float64\n",
      " 9   valence           587927 non-null  float64\n",
      " 10  tempo             587927 non-null  float64\n",
      " 11  time_signature    587927 non-null  int64  \n",
      "dtypes: float64(10), int64(2)\n",
      "memory usage: 53.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba15140",
   "metadata": {},
   "source": [
    "## Classifications\n",
    "We'll try to predict songs' popularities by categorizing popularities(into \"high\",\"mid\",\"low\"), and classifying songs into those categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d040236e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         (-0.001, 0.333]\n",
       "1         (-0.001, 0.333]\n",
       "2         (-0.001, 0.333]\n",
       "3         (-0.001, 0.333]\n",
       "4         (-0.001, 0.333]\n",
       "               ...       \n",
       "587922    (-0.001, 0.333]\n",
       "587923    (-0.001, 0.333]\n",
       "587924    (-0.001, 0.333]\n",
       "587925    (-0.001, 0.333]\n",
       "587926    (-0.001, 0.333]\n",
       "Name: popularity, Length: 587927, dtype: category\n",
       "Categories (3, interval[float64, right]): [(-0.001, 0.333] < (0.333, 0.667] < (0.667, 1.0]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(df['popularity'], bins=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a2292f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels=['low','medium', 'high']\n",
    "df['popularity']= pd.cut(df['popularity'], bins=3, labels=labels, right=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acf5c5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low       363052\n",
       "medium    213090\n",
       "high       11785\n",
       "Name: popularity, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.popularity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c973abe7",
   "metadata": {},
   "source": [
    "The dataset is unbalanced. This is intuitive, because there aren't as many popular songs as there are non-popular songs (otherwise, there will be much more financial stability in music industry!). However,imbalance in dataset will tamper with the accuracy of our model. One way to counteract this is by upsampling songs with high popularity.  We will then perform K-Nearest Neighbor classification, because they are good at handling noisy data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4d7b34",
   "metadata": {},
   "source": [
    "### Up-sampling songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "888636c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high= df[df.popularity=='high']\n",
    "df_mid= df[df.popularity=='medium']\n",
    "df_low= df[df.popularity=='low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aac5525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_low_upsampled= resample(df_low, replace=True, n_samples= 362633, random_state=42)\n",
    "df_mid_upsampled= resample(df_mid, replace=True, n_samples= 363052, random_state=42)\n",
    "df_high_upsampled= resample(df_high, replace=True, n_samples= 363052, random_state=42)\n",
    "\n",
    "# list_df_upsampled_tomid=[df_high_upsampled, df_mid, df_low_upsampled]\n",
    "list_df_upsampled_tohigh=[df_high_upsampled, df_mid_upsampled, df_low]\n",
    "\n",
    "# df_resampled= pd.concat(list_df_upsampled_tomid)\n",
    "df_resampled= pd.concat(list_df_upsampled_tohigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5b8254b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low       363052\n",
       "medium    363052\n",
       "high      363052\n",
       "Name: popularity, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled.popularity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab0cdc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_re= df_resampled.drop('popularity', axis=1)\n",
    "y_re= df_resampled['popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f8c2b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X_re, y_re, random_state= 42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6170820f",
   "metadata": {},
   "source": [
    "### Baseline Model- Random Prediction \n",
    "<br> We will randomly pull samples to serve as a baseline model to compare against different models we train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b99420b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_rand= shuffle(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9aa4f826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.33      0.33      0.33    108764\n",
      "         low       0.33      0.33      0.33    108706\n",
      "      medium       0.34      0.34      0.34    109277\n",
      "\n",
      "    accuracy                           0.33    326747\n",
      "   macro avg       0.33      0.33      0.33    326747\n",
      "weighted avg       0.33      0.33      0.33    326747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_rand))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c495f68c",
   "metadata": {},
   "source": [
    "### Testing Different Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611d5b57",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f9e4e84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.88      1.00      0.94    108764\n",
      "         low       0.66      0.54      0.60    108706\n",
      "      medium       0.63      0.65      0.64    109277\n",
      "\n",
      "    accuracy                           0.73    326747\n",
      "   macro avg       0.72      0.73      0.72    326747\n",
      "weighted avg       0.72      0.73      0.72    326747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "KNN= KNeighborsClassifier()\n",
    "\n",
    "KNN.fit(X_train, y_train)\n",
    "\n",
    "y_pred_classification= KNN.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_classification))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3eed6e",
   "metadata": {},
   "source": [
    "Because KNN is not a tree-based algorithm, it requires standardization. We will put it as part of our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82aa997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(n_neighbors):\n",
    "    StandardScaler()\n",
    "    n_neighbors= round(n_neighbors)\n",
    "\n",
    "    regressor= KNeighborsClassifier(n_neighbors= n_neighbors)\n",
    "\n",
    "    return np.mean(cross_validate(regressor, X_train, y_train, scoring='accuracy', error_score= 'raise', cv=5)['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d6b8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | n_neig... |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z9/t15ddpld70nc5qf41442lpr80000gn/T/ipykernel_5622/830115907.py:5: DeprecationWarning: \n",
      "Passing acquisition function parameters or gaussian process parameters to maximize\n",
      "is no longer supported, and will cause an error in future releases. Instead,\n",
      "please use the \"set_gp_params\" method to set the gp params, and pass an instance\n",
      " of bayes_opt.util.UtilityFunction using the acquisition_function argument\n",
      "\n",
      "  KNN_BO.maximize(n_iter=10, init_points=2, allow_duplicate_points=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.5566   \u001b[0m | \u001b[0m34.23    \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.5209   \u001b[0m | \u001b[0m49.22    \u001b[0m |\n"
     ]
    }
   ],
   "source": [
    "KNN_BO = BayesianOptimization(fit_model,{\n",
    "        'n_neighbors': (1,50)\n",
    "    })\n",
    "\n",
    "KNN_BO.maximize(n_iter=10, init_points=2, allow_duplicate_points=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899642fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(KNN_BO.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3631bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors= KNN_BO.max['params']['n_neighbors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfba240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors= round(n_neighbors))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535336c8",
   "metadata": {},
   "source": [
    "It's odd that our test performed better than our hyperparameter tuning. We will try n_neighbor with the next best accuracy: 1.565."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bb9661",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors= round(1.565))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c972b8b1",
   "metadata": {},
   "source": [
    "WOW! This is a huge improvement (though it probably is overfitting). Let's try Random Forest Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34a6267",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a268c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC= RandomForestClassifier(random_state= random_state)\n",
    "\n",
    "RFC.fit(X_train, y_train)\n",
    "y_rfc_pred= RFC.predict(X_test)\n",
    "print(classification_report(y_rfc_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc246484",
   "metadata": {},
   "source": [
    "Clearly, Random Forest Classifier performs best for our case. Let's use this model. Before fully delving into this model though, let's check for feature importance to see which features are more relevant for our task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c57c2ef",
   "metadata": {},
   "source": [
    "#### Random Forest Classification- Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f187a1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(n_estimators, min_samples_split, max_depth, max_leaf_nodes):\n",
    "    n_estimators= round(n_estimators)\n",
    "    min_samples_split= round(min_samples_split) \n",
    "    max_depth= round(max_depth)\n",
    "    max_leaf_nodes= round(max_leaf_nodes)\n",
    "\n",
    "    regressor= RandomForestClassifier(n_estimators= n_estimators, \n",
    "                                 min_samples_split= min_samples_split,\n",
    "                                 max_depth=max_depth,\n",
    "                                 random_state=random_state)\n",
    "\n",
    "    return np.mean(cross_validate(regressor, X_train, y_train, scoring='accuracy', error_score= 'raise', cv=5)['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244effcf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf_BO = BayesianOptimization(fit_model,{\n",
    "        'n_estimators': (1,1000),\n",
    "        'min_samples_split':(1.5,100), \n",
    "        'max_depth': (1,10),\n",
    "        'max_leaf_nodes': (2,10)\n",
    "    })\n",
    "\n",
    "rf_BO.maximize(n_iter=10, init_points=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2904dc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_BO.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef9ca50",
   "metadata": {},
   "source": [
    "Let's set optimized parameteres into variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5e4ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth= rf_BO.max['params']['max_depth']\n",
    "max_leaf_nodes= rf_BO.max['params']['max_leaf_nodes']\n",
    "min_samples_split= rf_BO.max['params']['min_samples_split']\n",
    "n_estimators= rf_BO.max['params']['n_estimators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53be2f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(max_depth= round(max_depth),\n",
    "    max_leaf_nodes= round(max_leaf_nodes),\n",
    "    min_samples_split= round(min_samples_split),\n",
    "    n_estimators=round(n_estimators))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0f6c27",
   "metadata": {},
   "source": [
    "Through hyperparameter tuning, we learned that random forest classification model can expect target score of 0.66. This score is reasonable, as the model is expected to perform better on training set. However, our current target score is still great. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295e7b2b",
   "metadata": {},
   "source": [
    "Clearly, KNN classifier performs better, with accuracy score of 0.82. Although we have a model performance of 0.82, it is possible that the model is overfitting. However, given different iterations of the model, you can expect it to reliably predict anywhere between 60 to 70% accuracy. We have come a long way from the baseline model of 0.33 accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
